import json
import math
import re
from datetime import datetime, timedelta, timezone
from pathlib import Path

import requests
import feedparser
from bs4 import BeautifulSoup
from finance_calendars import finance_calendars as fc

ROOT = Path(__file__).resolve().parents[1]
OUT = ROOT / "data" / "latest.json"
OUT.parent.mkdir(parents=True, exist_ok=True)

KST = timezone(timedelta(hours=9))

MY_TICKERS = ["NE","RXRX","BLDP","BMNR","NVDA","TSLA","AI","GGLL","QQQM","VRTL","CEVA","CCS"]

KO_NAME = {
    "NE":"ë…¸ë¸” ì½”í¼ë ˆì´ì…˜",
    "RXRX":"ë¦¬ì»¤ì „ íŒŒë§ˆ",
    "BLDP":"ë°œë¼ë“œ íŒŒì›Œ",
    "BMNR":"ë¹„íŠ¸ë§ˆì¸ë“œ(ê°€ì¹­)",
    "NVDA":"ì—”ë¹„ë””ì•„",
    "TSLA":"í…ŒìŠ¬ë¼",
    "AI":"C3.ai",
    "GGLL":"ê·¸ë˜ë‹›ì…°ì–´ì¦ˆ 2x ë¡± NVDA(ETF)",
    "QQQM":"ì¸ë² ìŠ¤ì½” ë‚˜ìŠ¤ë‹¥100 ë¯¸ë‹ˆ(ETF)",
    "VRTL":"ë²„ì¶”ì–¼íŠ¸â€¦(ê°€ì¹­)",
    "CEVA":"ì„¸ë°”",
    "CCS":"ì„¼ì¶”ë¦¬ ì»¤ë®¤ë‹ˆí‹°ì¦ˆ",
}

SECTOR_ETFS = [
    ("XLK", "ê¸°ìˆ "),
    ("XLF", "ê¸ˆìœµ"),
    ("XLY", "ê²½ê¸°ì†Œë¹„ì¬"),
    ("XLP", "í•„ìˆ˜ì†Œë¹„ì¬"),
    ("XLE", "ì—ë„ˆì§€"),
    ("XLV", "í—¬ìŠ¤ì¼€ì–´"),
    ("XLI", "ì‚°ì—…ì¬"),
    ("XLB", "ì†Œì¬"),
    ("XLU", "ìœ í‹¸ë¦¬í‹°"),
    ("XLRE", "ë¶€ë™ì‚°"),
    ("XLC", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"),
]

UA_HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
}

def safe_float(x):
    try:
        return float(x)
    except Exception:
        return None

def pct_change(last, prev):
    if last is None or prev is None or prev == 0:
        return 0.0
    return (last / prev - 1.0) * 100.0

def stooq_csv(symbol: str) -> str:
    # Stooq CSV endpoint (daily)
    return f"https://stooq.com/q/d/l/?s={symbol}&i=d"

def fetch_stooq_close_series(symbol: str, limit: int = 35):
    """
    returns (labels(list[str]), closes(list[float]))
    """
    url = stooq_csv(symbol.lower())
    r = requests.get(url, headers=UA_HEADERS, timeout=25)
    r.raise_for_status()
    lines = r.text.strip().splitlines()
    if len(lines) < 3:
        return [], []
    # header: Date,Open,High,Low,Close,Volume
    rows = []
    for line in lines[1:]:
        parts = line.split(",")
        if len(parts) < 5:
            continue
        dt = parts[0].strip()
        close = safe_float(parts[4])
        if close is None:
            continue
        rows.append((dt, close))
    rows = rows[-limit:]
    labels = [d for d, _ in rows]
    closes = [c for _, c in rows]
    return labels, closes

def fetch_fred_dgs10(limit: int = 35):
    # no key needed
    url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=DGS10"
    r = requests.get(url, headers=UA_HEADERS, timeout=25)
    r.raise_for_status()
    lines = r.text.strip().splitlines()
    rows = []
    for line in lines[1:]:
        d, v = line.split(",")
        val = safe_float(v)  # already percent
        if val is None:
            continue
        rows.append((d.strip(), val))
    rows = rows[-limit:]
    labels = [d for d, _ in rows]
    vals = [v for _, v in rows]
    return labels, vals

def google_news_rss(query: str, max_items: int = 10):
    # Google News RSS
    # NOTE: query should be url-escaped minimally (spaces -> +)
    q = query.replace(" ", "+")
    url = f"https://news.google.com/rss/search?q={q}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    items = []
    for e in feed.entries[:max_items]:
        title = getattr(e, "title", "").strip()
        # source often embedded like " - Reuters"
        source = ""
        if " - " in title:
            source = title.split(" - ")[-1].strip()
        summary = re.sub(r"\s+", " ", re.sub("<[^>]+>", "", getattr(e, "summary", "")).strip())
        items.append({
            "title": title,
            "why": summary[:140] + ("â€¦" if len(summary) > 140 else ""),
            "source": source or "Google News",
            "star": False,
        })
    # de-dup by title
    seen = set()
    out = []
    for it in items:
        key = it["title"].lower()
        if not key or key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out[:5]

def fetch_fed_schedule(limit: int = 6):
    # Use Fed "Monetary Policy" upcoming dates (contains FOMC meeting + minutes)
    url = "https://www.federalreserve.gov/monetarypolicy.htm"
    r = requests.get(url, headers=UA_HEADERS, timeout=25)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    text = soup.get_text("\n")
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    # crude parse: find "Upcoming Dates" block
    try:
        idx = lines.index("Upcoming Dates")
    except ValueError:
        return []
    block = lines[idx: idx + 80]
    events = []
    # pattern: "Jan. 27-28 FOMC Meeting" etc
    for ln in block:
        if len(events) >= limit:
            break
        if "FOMC" in ln or "Minutes" in ln:
            events.append(ln)
    # format into UI rows
    out = []
    for ev in events[:limit]:
        # split into date + title
        m = re.match(r"^([A-Za-z]{3,4}\.\s*\d{1,2}(?:-\d{1,2})?)\s+(.*)$", ev)
        if m:
            dpart = m.group(1)
            title = m.group(2)
            out.append({"time": dpart, "title": title, "note": "Fed(ê³µì‹ ìº˜ë¦°ë”)"})
        else:
            out.append({"time": "-", "title": ev, "note": "Fed(ê³µì‹ ìº˜ë¦°ë”)"})
    return out

def build_earnings_next_7days(myset):
    items = []
    today = datetime.now(KST).date()
    for i in range(0, 7):
        d = today + timedelta(days=i)
        try:
            rows = fc.get_earnings_by_date(datetime(d.year, d.month, d.day, 0, 0))
        except Exception:
            rows = []
        # rows: list[dict]
        for r in rows:
            sym = str(r.get("symbol") or r.get("Symbol") or "").upper().strip()
            name = str(r.get("name") or r.get("Name") or "").strip()
            timing = str(r.get("time") or r.get("Time") or r.get("timing") or "").strip()  # BMO/AMC sometimes
            if sym in myset:
                when = f"{d.isoformat()} {timing}".strip()
                items.append({
                    "when": when,
                    "symbol": sym,
                    "name": name or KO_NAME.get(sym, ""),
                    "note": "ì‹¤ì  ìº˜ë¦°ë”(Nasdaq)",
                })
    return items[:12]

def main():
    now_kst = datetime.now(KST)
    updated_at = now_kst.strftime("%Y-%m-%d %H:%M KST")

    # Indices / VIX
    spx_labels, spx = fetch_stooq_close_series("^spx", 35)
    ndq_labels, ixic = fetch_stooq_close_series("^ndq", 35)
    dji_labels, dji = fetch_stooq_close_series("^dji", 35)
    vix_labels, vix = fetch_stooq_close_series("vi.f", 35)

    def last_prev(arr):
        if len(arr) < 2:
            return None, None
        return arr[-1], arr[-2]

    spx_last, spx_prev = last_prev(spx)
    ixic_last, ixic_prev = last_prev(ixic)
    dji_last, dji_prev = last_prev(dji)
    vix_last, vix_prev = last_prev(vix)

    overnight_kpis = [
        {"icon":"ğŸ“ˆ","label":"S&P500","valueText": f"{spx_last:,.2f}" if spx_last else "-", "desc":"ëŒ€í‘œ ì§€ìˆ˜", "changePct": round(pct_change(spx_last, spx_prev), 2) if spx_last else 0},
        {"icon":"ğŸ“ˆ","label":"ë‚˜ìŠ¤ë‹¥","valueText": f"{ixic_last:,.2f}" if ixic_last else "-", "desc":"ê¸°ìˆ ì£¼ ë¹„ì¤‘", "changePct": round(pct_change(ixic_last, ixic_prev), 2) if ixic_last else 0},
        {"icon":"ğŸ“ˆ","label":"ë‹¤ìš°","valueText": f"{dji_last:,.2f}" if dji_last else "-", "desc":"ëŒ€í˜• ê°€ì¹˜ì£¼", "changePct": round(pct_change(dji_last, dji_prev), 2) if dji_last else 0},
        {"icon":"ğŸ˜±","label":"VIX","valueText": f"{vix_last:,.2f}" if vix_last else "-", "desc":"ë¶ˆì•ˆí•˜ë©´ â†‘", "changePct": round(pct_change(vix_last, vix_prev), 2) if vix_last else 0},
    ]

    # Macro: US10Y (FRED), DXY (DX.F), WTI (CL.F)
    us10y_labels, us10y = fetch_fred_dgs10(35)
    dxy_labels, dxy = fetch_stooq_close_series("dx.f", 35)
    wti_labels, wti = fetch_stooq_close_series("cl.f", 35)

    us10y_last, us10y_prev = last_prev(us10y)
    dxy_last, dxy_prev = last_prev(dxy)
    wti_last, wti_prev = last_prev(wti)

    macro_kpis = [
        {"icon":"ğŸ¦","label":"ë¯¸êµ­ 10ë…„ ê¸ˆë¦¬","valueText": f"{us10y_last:.2f}%" if us10y_last else "-", "desc":"FRED(DGS10)", "changePct": round(pct_change(us10y_last, us10y_prev), 2) if us10y_last else 0},
        {"icon":"ğŸ’µ","label":"ë‹¬ëŸ¬ê°’(DXY)","valueText": f"{dxy_last:.2f}" if dxy_last else "-", "desc":"Stooq(DX.F)", "changePct": round(pct_change(dxy_last, dxy_prev), 2) if dxy_last else 0},
        {"icon":"ğŸ›¢ï¸","label":"ìœ ê°€(WTI)","valueText": f"{wti_last:.2f}" if wti_last else "-", "desc":"Stooq(CL.F)", "changePct": round(pct_change(wti_last, wti_prev), 2) if wti_last else 0},
    ]

    # align macro labels by us10y labels for chart (simple approach)
    labels = us10y_labels[-30:] if us10y_labels else (spx_labels[-30:] if spx_labels else [])
    # build lookup dict for dxy/wti by date
    dxy_map = {d: v for d, v in zip(dxy_labels, dxy)}
    wti_map = {d: v for d, v in zip(wti_labels, wti)}
    us10y_map = {d: v for d, v in zip(us10y_labels, us10y)}
    macro_series = {
        "labels": labels,
        "us10y": [us10y_map.get(d) for d in labels],
        "dxy": [dxy_map.get(d) for d in labels],
        "wti": [wti_map.get(d) for d in labels],
    }

    # My stocks (Stooq: ticker.us)
    mystocks = []
    my_changes = []
    for t in MY_TICKERS:
        sym = t.upper()
        stooq_sym = f"{sym.lower()}.us"
        lbls, closes = fetch_stooq_close_series(stooq_sym, 3)
        last, prev = last_prev(closes)
        chg = round(pct_change(last, prev), 2) if last and prev else 0.0
        my_changes.append((sym, chg))
        last_txt = f"{last:.2f}" if last else "-"
        price_text = f"${last_txt} ({'â†‘' if chg>=0 else 'â†“'}{abs(chg):.2f}%)" if last else "-"
        mystocks.append({
            "symbol": sym,
            "name": KO_NAME.get(sym, ""),
            "koName": KO_NAME.get(sym, ""),
            "last": last_txt if last else "-",
            "changePct": chg,
            "priceText": price_text,
            "news": "",
            "nextEvent": "",
            "memo": "",
        })

    # Sectors from SPDR sector ETFs
    sectors = []
    for etf, ko in SECTOR_ETFS:
        lbls, closes = fetch_stooq_close_series(f"{etf.lower()}.us", 3)
        last, prev = last_prev(closes)
        chg = round(pct_change(last, prev), 2) if last and prev else 0.0
        sectors.append({"name": ko, "changePct": chg, "symbol": etf})

    # Earnings (next 7 days, my tickers only)
    myset = set(MY_TICKERS)
    upcoming = build_earnings_next_7days(myset)

    # Movers: use myStocks top/bottom as "ê¸‰ë“±ë½" (ì‹¤ì  ì„¹ì…˜ì˜ ëŒ€ì²´ ì¹´ë“œ)
    my_sorted = sorted(mystocks, key=lambda x: x.get("changePct", 0), reverse=True)
    movers = []
    for x in (my_sorted[:3] + my_sorted[-3:]):
        movers.append({
            "symbol": x["symbol"],
            "name": x.get("name",""),
            "changePct": x.get("changePct", 0),
            "why": "ë‚´ ì¢…ëª© ê¸°ì¤€ ê¸‰ë“±ë½(í”„ë¡ì‹œ) â€” ì‹¤ì  ì—°ë™ ì—¬ë¶€ëŠ” ë‰´ìŠ¤ í™•ì¸",
        })

    # Schedule
    fed_events = fetch_fed_schedule(6)
    # econ: ë„£ì„ë§Œí•œ ë¬´ë£Œ ì •ì‹ ìº˜ë¦°ë”ê°€ ë¹¡ì„¸ì„œ, v1ì€ "ë‚´ ì¢…ëª© ì‹¤ì /ì£¼ìš” ì´ë²¤íŠ¸"ë¡œ ì±„ì›€
    econ_events = []
    for u in upcoming[:6]:
        econ_events.append({"time": u["when"].split()[0], "title": f"Earnings: {u['symbol']}", "note": u.get("name","")})
    if not econ_events:
        econ_events = []

    # News Top5 (market general + tickers mix)
    news = google_news_rss("US stock market futures S&P 500", 12)
    if len(news) < 5:
        extra = google_news_rss("Nasdaq earnings", 12)
        news = (news + extra)[:5]

    # Mood/Action simple rule
    spx_chg = pct_change(spx_last, spx_prev) if spx_last and spx_prev else 0
    vix_val = vix_last if vix_last else None
    if spx_chg > 0.5 and (vix_val is None or vix_val < 18):
        mood = {"value": "ì¢‹ìŒ", "reason": "ì§€ìˆ˜ ê°•ì„¸ + ë³€ë™ì„± ë‚®ì€ í¸"}
        action = {"value": "ë§¤ìˆ˜(ì¡°ê¸ˆ)", "note": "ë¶„í• /ì†Œì•¡ ì¤‘ì‹¬", "beginnerMemo": "ê¸‰í• ìˆ˜ë¡ ë¶„í• . í•œ ë²ˆì— ì˜¬ì¸ ê¸ˆì§€."}
    elif spx_chg < -0.5 and (vix_val is not None and vix_val > 20):
        mood = {"value": "ë‚˜ì¨", "reason": "ì§€ìˆ˜ ì•½ì„¸ + ë³€ë™ì„± ìƒìŠ¹"}
        action = {"value": "ê´€ë§", "note": "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ìš°ì„ ", "beginnerMemo": "ì†ì‹¤ ì¤„ì´ëŠ” ë‚ ì´ ì§„ì§œ ìˆ˜ìµ."}
    else:
        mood = {"value": "ì• ë§¤", "reason": "ë°©í–¥ì„± ì•½í•¨(ë³´í•©/í˜¼ì¡°)"}
        action = {"value": "ê´€ë§", "note": "í™•ì‹¤í•œ êµ¬ê°„ê¹Œì§€ ê¸°ë‹¤ë¦¬ê¸°", "beginnerMemo": "ê´€ë§ë„ ì „ëµ. ì• ë§¤í•˜ë©´ ì‰¬ëŠ” ê²Œ ì´ê¹€."}

    # One-line summary
    top = max(mystocks, key=lambda x: x.get("changePct", 0), default=None)
    bot = min(mystocks, key=lambda x: x.get("changePct", 0), default=None)
    one_line = (
        f"ì§€ìˆ˜ {('ìƒìŠ¹' if spx_chg>=0 else 'í•˜ë½')}({spx_chg:+.2f}%), "
        f"10Y {pct_change(us10y_last, us10y_prev):+.2f}%, "
        f"DXY {pct_change(dxy_last, dxy_prev):+.2f}%, "
        f"WTI {pct_change(wti_last, wti_prev):+.2f}%. "
        f"ë‚´ ì¢…ëª© TOP: {top['symbol']}({top['changePct']:+.2f}%) / "
        f"BOT: {bot['symbol']}({bot['changePct']:+.2f}%)."
        if top and bot else "ìë™ ì—…ë°ì´íŠ¸: ì§€ìˆ˜/ê¸ˆë¦¬/ë‹¬ëŸ¬/ìœ ê°€ + ë‚´ ì¢…ëª© ë³€ë™ ë°˜ì˜"
    )

    # Risk
    max_abs = max((abs(x.get("changePct",0)) for x in mystocks), default=0)
    risk = {
        "speed": f"ë‚´ ì¢…ëª© ìµœëŒ€ ì ˆëŒ€ë“±ë½: {max_abs:.2f}%",
        "vol": f"VIX: {vix_last:.2f}" if vix_last else "VIX: -",
        "rule": f"ì˜¤ëŠ˜ ì•¡ì…˜: {action['value']} (ë¬´ë¦¬ ê¸ˆì§€)",
    }

    # Overnight series (30)
    ov_labels = spx_labels[-30:] if spx_labels else []
    # align other indices by date
    ixic_map = {d: v for d, v in zip(ndq_labels, ixic)}
    dji_map = {d: v for d, v in zip(dji_labels, dji)}
    overnight_series = {
        "labels": ov_labels,
        "spx": [v for v in spx[-30:]] if spx else [],
        "ixic": [ixic_map.get(d) for d in ov_labels],
        "dji": [dji_map.get(d) for d in ov_labels],
    }

    payload = {
        "updatedAt": updated_at,
        "oneLine": one_line,
        "mood": mood,
        "action": action,
        "overnight": {
            "kpis": overnight_kpis,
            "bigFlowReason": "ë¬´ë£Œ ë°ì´í„° ê¸°ë°˜ ìë™ ìƒì„±(v1): ì§€ìˆ˜/ë³€ë™ì„±/ê¸ˆë¦¬/ë‹¬ëŸ¬/ìœ ê°€ + ë‚´ ì¢…ëª© ê¸‰ë“±ë½ì„ ê²°í•©",
            "series": overnight_series,
        },
        "schedule": {"econ": econ_events, "fed": fed_events},
        "macro": {"kpis": macro_kpis, "series": macro_series},
        "newsTop5": news,
        "earnings": {"upcoming": upcoming, "movers": movers},
        "sectors": [{"name": x["name"], "changePct": x["changePct"]} for x in sectors],
        "myStocks": mystocks,
        "risk": risk,
        "todo3": [
            "ë‚´ ì¢…ëª© ë³€ë™ ìƒìœ„/í•˜ìœ„ 3ê°œë§Œ ë”°ë¡œ ì²´í¬",
            "ê¸‰ë“±/ê¸‰ë½ ì¢…ëª©ì€ ë‰´ìŠ¤ í™•ì¸ í›„ ëŒ€ì‘",
            "ì˜¤ëŠ˜ì€ â€˜í•œ ë²ˆë§Œâ€™ ë§¤ë§¤ ê·œì¹™ ì§€í‚¤ê¸°"
        ],
    }

    OUT.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    print("Wrote:", OUT)

if __name__ == "__main__":
    main()
